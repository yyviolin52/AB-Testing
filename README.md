# AB-Testing
AB Testing Using Python

The A/B testing Experiment would like to discover whether a local translation of Spanish is better than the standard Spanish translation.

Null Hypothesis: There is no conversion change between standard translation and localized translation.

Alternative Hypothesis: There is a statistical significance conversion change between standard translation and localized translation.

Scenario, after running the experiment 5 days later, the team surprisingly found that the test is negative. It appears that the non-localized translation was doing better!

In this kernel we would like to solve:

1. Confirm that the test is actually negative. That is, it appears that the old version of the site with just one translation across Spain and LatAm performs better.

2. Explain why that might be happening. Are the localized translations really worse?

